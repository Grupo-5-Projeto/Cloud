{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18a0fdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib64/python3.7/site-packages (1.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib64/python3.7/site-packages (from pandas) (1.21.6)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'pandas' instalado com sucesso.\n",
      "Requirement already satisfied: gspread==3.6.0 in /usr/local/lib/python3.7/site-packages (3.6.0)\n",
      "Requirement already satisfied: requests>=2.2.1 in /usr/local/lib/python3.7/site-packages (from gspread==3.6.0) (2.31.0)\n",
      "Requirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.7/site-packages (from gspread==3.6.0) (2.40.3)\n",
      "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.7/site-packages (from gspread==3.6.0) (0.4.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/site-packages (from google-auth>=1.12.0->gspread==3.6.0) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/site-packages (from google-auth>=1.12.0->gspread==3.6.0) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/site-packages (from google-auth>=1.12.0->gspread==3.6.0) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/site-packages (from google-auth-oauthlib>=0.4.1->gspread==3.6.0) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib64/python3.7/site-packages (from requests>=2.2.1->gspread==3.6.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests>=2.2.1->gspread==3.6.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests>=2.2.1->gspread==3.6.0) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests>=2.2.1->gspread==3.6.0) (2025.4.26)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread==3.6.0) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread==3.6.0) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'gspread==3.6.0' instalado com sucesso.\n",
      "Requirement already satisfied: google-auth-oauthlib==0.4.6 in /usr/local/lib/python3.7/site-packages (0.4.6)\n",
      "Requirement already satisfied: google-auth>=1.0.0 in /usr/local/lib/python3.7/site-packages (from google-auth-oauthlib==0.4.6) (2.40.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/site-packages (from google-auth-oauthlib==0.4.6) (2.0.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/site-packages (from google-auth>=1.0.0->google-auth-oauthlib==0.4.6) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/site-packages (from google-auth>=1.0.0->google-auth-oauthlib==0.4.6) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/site-packages (from google-auth>=1.0.0->google-auth-oauthlib==0.4.6) (4.9.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib==0.4.6) (3.2.2)\n",
      "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib==0.4.6) (2.31.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.0->google-auth-oauthlib==0.4.6) (0.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib64/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib==0.4.6) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib==0.4.6) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib==0.4.6) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib==0.4.6) (2025.4.26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'google-auth-oauthlib==0.4.6' instalado com sucesso.\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/site-packages (1.33.13)\n",
      "Requirement already satisfied: botocore<1.34.0,>=1.33.13 in /usr/local/lib/python3.7/site-packages (from boto3) (1.33.13)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.9.0,>=0.8.2 in /usr/local/lib/python3.7/site-packages (from boto3) (0.8.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/site-packages (from botocore<1.34.0,>=1.33.13->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/site-packages (from botocore<1.34.0,>=1.33.13->boto3) (1.26.20)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.34.0,>=1.33.13->boto3) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'boto3' instalado com sucesso.\n",
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.7/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      "com.amazonaws#aws-java-sdk-bundle added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-baa17a85-d3cc-4531-9cb5-5cd9ed114d45;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.4 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.12.262 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      ":: resolution report :: resolve 313ms :: artifacts dl 19ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.12.262 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.4 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.901 by [com.amazonaws#aws-java-sdk-bundle;1.12.262] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   4   |   0   |   0   |   1   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-baa17a85-d3cc-4531-9cb5-5cd9ed114d45\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/8ms)\n",
      "25/06/13 20:07:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "/usr/local/lib/python3.7/site-packages/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n",
      "25/06/13 20:07:17 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DataFrames Iniciais ---\n",
      "Schema de TabelaCompleta:\n",
      "root\n",
      " |-- data_hora: string (nullable = true)\n",
      " |-- valor: string (nullable = true)\n",
      " |-- fk_sensor: string (nullable = true)\n",
      " |-- fk_unid_medida: string (nullable = true)\n",
      " |-- fk_paciente: string (nullable = true)\n",
      " |-- fk_upa: string (nullable = true)\n",
      "\n",
      "Amostra de TabelaCompleta:\n",
      "+-------------------+-----+---------+--------------+-----------+------+\n",
      "|data_hora          |valor|fk_sensor|fk_unid_medida|fk_paciente|fk_upa|\n",
      "+-------------------+-----+---------+--------------+-----------+------+\n",
      "|2025-06-01T00:05:00|23   |1        |null          |null       |1     |\n",
      "|2025-06-01T00:10:00|21   |1        |null          |null       |1     |\n",
      "|2025-06-01T00:15:00|19   |1        |null          |null       |1     |\n",
      "|2025-06-01T00:20:00|18   |1        |null          |null       |1     |\n",
      "|2025-06-01T00:25:00|15   |1        |null          |null       |1     |\n",
      "+-------------------+-----+---------+--------------+-----------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Schema de paciente_df:\n",
      "root\n",
      " |-- id_paciente: string (nullable = true)\n",
      " |-- nome: string (nullable = true)\n",
      " |-- cpf: string (nullable = true)\n",
      " |-- data_nascimento: string (nullable = true)\n",
      " |-- biometria: string (nullable = true)\n",
      "\n",
      "Amostra de paciente_df:\n",
      "+-----------+--------------+-----------+---------------+---------+\n",
      "|id_paciente|nome          |cpf        |data_nascimento|biometria|\n",
      "+-----------+--------------+-----------+---------------+---------+\n",
      "|1          |Ana Souza     |22813945182|2015-05-12     |0780K1VE |\n",
      "|2          |Bruno Oliveira|93526748006|2017-08-23     |07COZN1Z |\n",
      "|3          |Carlos Pereira|30659423739|2012-11-30     |09MV3X8F |\n",
      "|4          |Daniela Lima  |15362784900|2016-03-14     |0BXS4DND |\n",
      "|5          |Eduardo Santos|96283104517|2014-07-21     |0CD10R5D |\n",
      "+-----------+--------------+-----------+---------------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "--- Processamento para o Sensor 5 (Biometria) ---\n",
      "\n",
      "DataFrame df_biometria após filtro e remoção de nulos:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+---------+--------------+-----------+------+\n",
      "|data_hora          |valor   |fk_sensor|fk_unid_medida|fk_paciente|fk_upa|\n",
      "+-------------------+--------+---------+--------------+-----------+------+\n",
      "|2025-06-01T00:00:00|4H23NL0F|5        |null          |77         |1     |\n",
      "|2025-06-01T00:05:00|2FHPLMD1|5        |null          |42         |1     |\n",
      "|2025-06-01T00:10:00|4S10DF75|5        |null          |88         |1     |\n",
      "|2025-06-01T00:15:00|4YK4US1Y|5        |null          |90         |1     |\n",
      "|2025-06-01T00:20:00|1VKADGXU|5        |null          |27         |1     |\n",
      "+-------------------+--------+---------+--------------+-----------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "DataFrame df_biometria após cast e normalização de 'valor':\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+---------+--------------+-----------+------+\n",
      "|data_hora          |valor   |fk_sensor|fk_unid_medida|fk_paciente|fk_upa|\n",
      "+-------------------+--------+---------+--------------+-----------+------+\n",
      "|2025-06-01 00:00:00|4h23nl0f|5        |null          |77         |1     |\n",
      "|2025-06-01 00:05:00|2fhplmd1|5        |null          |42         |1     |\n",
      "|2025-06-01 00:10:00|4s10df75|5        |null          |88         |1     |\n",
      "|2025-06-01 00:15:00|4yk4us1y|5        |null          |90         |1     |\n",
      "|2025-06-01 00:20:00|1vkadgxu|5        |null          |27         |1     |\n",
      "+-------------------+--------+---------+--------------+-----------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- data_hora: timestamp (nullable = true)\n",
      " |-- valor: string (nullable = true)\n",
      " |-- fk_sensor: string (nullable = true)\n",
      " |-- fk_unid_medida: string (nullable = true)\n",
      " |-- fk_paciente: string (nullable = true)\n",
      " |-- fk_upa: integer (nullable = true)\n",
      "\n",
      "\n",
      "DataFrame df_biometria_agrupado:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+----------------------+------+\n",
      "|valor   |data_biometria|primeira_data_hora_dia|fk_upa|\n",
      "+--------+--------------+----------------------+------+\n",
      "|03ju5bwm|2025-05-20    |2025-05-20 00:30:00   |1     |\n",
      "|06kgrt2a|2025-05-20    |2025-05-20 01:00:00   |1     |\n",
      "|0780k1ve|2025-05-20    |2025-05-20 00:00:00   |1     |\n",
      "|07cozn1z|2025-05-20    |2025-05-20 02:15:00   |11    |\n",
      "|09mv3x8f|2025-05-20    |2025-05-20 00:45:00   |1     |\n",
      "+--------+--------------+----------------------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- valor: string (nullable = true)\n",
      " |-- data_biometria: date (nullable = true)\n",
      " |-- primeira_data_hora_dia: timestamp (nullable = true)\n",
      " |-- fk_upa: integer (nullable = true)\n",
      "\n",
      "\n",
      "DataFrame paciente_df_normalized com 'biometria_join' (após normalização):\n",
      "+---------+--------------+--------------+---------------+\n",
      "|biometria|biometria_join|nome          |data_nascimento|\n",
      "+---------+--------------+--------------+---------------+\n",
      "|0780K1VE |0780k1ve      |Ana Souza     |2015-05-12     |\n",
      "|07COZN1Z |07cozn1z      |Bruno Oliveira|2017-08-23     |\n",
      "|09MV3X8F |09mv3x8f      |Carlos Pereira|2012-11-30     |\n",
      "|0BXS4DND |0bxs4dnd      |Daniela Lima  |2016-03-14     |\n",
      "|0CD10R5D |0cd10r5d      |Eduardo Santos|2014-07-21     |\n",
      "|0KUFS4QJ |0kufs4qj      |Luiza Amaral  |2018-03-19     |\n",
      "|0NRSR3NA |0nrsr3na      |Miguel Tavares|2020-07-25     |\n",
      "|0RFDCAX5 |0rfdcax5      |Nina Cardoso  |2014-10-01     |\n",
      "|0S09SUA0 |0s09sua0      |Otávio Luz    |2013-12-11     |\n",
      "|0S91MLSO |0s91mlso      |Pietra Moraes |2019-01-30     |\n",
      "+---------+--------------+--------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "DataFrame df_biometria_final após o JOIN (antes de calcular idade):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+----------------------+------+---------------+---------------+------------+\n",
      "|valor   |data_biometria|primeira_data_hora_dia|fk_upa|data_nascimento|nome_paciente  |cpf_paciente|\n",
      "+--------+--------------+----------------------+------+---------------+---------------+------------+\n",
      "|cet7th6t|2025-06-01    |2025-06-01 00:40:00   |2     |2009-03-03     |Beatriz Helena |10987654316 |\n",
      "|owclfl5x|2025-06-01    |2025-06-01 00:05:00   |4     |1965-10-15     |Antônio Rocha  |23456789012 |\n",
      "|s5cjywyv|2025-06-01    |2025-06-01 00:25:00   |4     |1965-07-03     |Pedro Gabriel  |89012345678 |\n",
      "|xy4c2qn1|2025-06-01    |2025-06-01 01:55:00   |5     |1958-10-26     |Félix Henrique |01234567890 |\n",
      "|2cuymv1u|2025-05-30    |2025-05-30 02:50:00   |1     |2017-09-11     |Júlia Ribeiro  |98765432109 |\n",
      "|h07cfh59|2025-05-30    |2025-05-30 00:50:00   |3     |1985-07-12     |Mariana Santana|88864216905 |\n",
      "|wayk4e05|2025-05-30    |2025-05-30 00:20:00   |9     |1960-07-10     |Lídia Lima     |89012345678 |\n",
      "|ormn0tnp|2025-05-28    |2025-05-28 02:00:00   |4     |1979-07-20     |Simone Maria   |66778899001 |\n",
      "|bh8bqbgw|2025-05-26    |2025-05-26 05:15:00   |2     |2009-05-05     |Luiz Felipe    |32109876539 |\n",
      "|hotzpgnr|2025-05-26    |2025-05-26 04:10:00   |3     |1996-02-04     |Juliana Santana|12326438526 |\n",
      "+--------+--------------+----------------------+------+---------------+---------------+------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "root\n",
      " |-- valor: string (nullable = true)\n",
      " |-- data_biometria: date (nullable = true)\n",
      " |-- primeira_data_hora_dia: timestamp (nullable = true)\n",
      " |-- fk_upa: integer (nullable = true)\n",
      " |-- data_nascimento: string (nullable = true)\n",
      " |-- nome_paciente: string (nullable = true)\n",
      " |-- cpf_paciente: string (nullable = true)\n",
      "\n",
      "\n",
      "Contagem de nulos em colunas chave após o JOIN:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------------------+------------------+\n",
      "|nulos_nome_paciente|nulos_data_nascimento|nulos_cpf_paciente|\n",
      "+-------------------+---------------------+------------------+\n",
      "|                  0|                    0|                 0|\n",
      "+-------------------+---------------------+------------------+\n",
      "\n",
      "\n",
      "--- DataFrame Final de Biometria ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+--------------+------------+--------------+--------------+----------+------+\n",
      "|valor   |nome_paciente     |idade_paciente|Faixa_Etaria|data_biometria|hora_biometria|Faixa_Hora|fk_upa|\n",
      "+--------+------------------+--------------+------------+--------------+--------------+----------+------+\n",
      "|cet7th6t|Beatriz Helena    |16            |13–17       |2025-06-01    |00:40:00      |0–6h      |2     |\n",
      "|owclfl5x|Antônio Rocha     |59            |40–59       |2025-06-01    |00:05:00      |0–6h      |4     |\n",
      "|s5cjywyv|Pedro Gabriel     |59            |40–59       |2025-06-01    |00:25:00      |0–6h      |4     |\n",
      "|xy4c2qn1|Félix Henrique    |66            |60+         |2025-06-01    |01:55:00      |0–6h      |5     |\n",
      "|2cuymv1u|Júlia Ribeiro     |7             |0–12        |2025-05-30    |02:50:00      |0–6h      |1     |\n",
      "|h07cfh59|Mariana Santana   |39            |18–39       |2025-05-30    |00:50:00      |0–6h      |3     |\n",
      "|wayk4e05|Lídia Lima        |64            |60+         |2025-05-30    |00:20:00      |0–6h      |9     |\n",
      "|ormn0tnp|Simone Maria      |45            |40–59       |2025-05-28    |02:00:00      |0–6h      |4     |\n",
      "|bh8bqbgw|Luiz Felipe       |16            |13–17       |2025-05-26    |05:15:00      |0–6h      |2     |\n",
      "|hotzpgnr|Juliana Santana   |29            |18–39       |2025-05-26    |04:10:00      |0–6h      |3     |\n",
      "|e5s51k2i|Isabela Luana     |16            |13–17       |2025-05-26    |03:05:00      |0–6h      |3     |\n",
      "|oehxxbqs|Carlos Pereira    |58            |40–59       |2025-05-26    |00:05:00      |0–6h      |4     |\n",
      "|4nyyog5o|Davi Lucca        |7             |0–12        |2025-05-29    |02:35:00      |0–6h      |1     |\n",
      "|2vw5wxam|Laura Almeida     |11            |0–12        |2025-05-29    |05:10:00      |0–6h      |1     |\n",
      "|2v6zo2ya|Pedro Rocha       |6             |0–12        |2025-05-20    |00:15:00      |0–6h      |1     |\n",
      "|9fl5lsn9|Victor Hugo       |17            |13–17       |2025-05-20    |03:35:00      |0–6h      |2     |\n",
      "|fxlo975x|Gisele Farias     |39            |18–39       |2025-05-20    |02:25:00      |0–6h      |3     |\n",
      "|pmlh983q|Maria Eduarda     |44            |40–59       |2025-05-20    |00:00:00      |0–6h      |4     |\n",
      "|urlng0pf|Ricardo Rocha     |77            |60+         |2025-05-27    |01:35:00      |0–6h      |5     |\n",
      "|vh2fjppr|Neuza Gomes       |68            |60+         |2025-05-27    |01:15:00      |0–6h      |5     |\n",
      "|vpjb3t4f|Márcia Costa      |64            |60+         |2025-05-27    |00:55:00      |0–6h      |5     |\n",
      "|5yeoli21|Lucas Rafael      |10            |0–12        |2025-06-01    |01:05:00      |0–6h      |1     |\n",
      "|8ba932et|Maria Eduarda     |14            |13–17       |2025-06-01    |00:40:00      |0–6h      |2     |\n",
      "|eou72z2f|Hugo Martins      |28            |18–39       |2025-06-01    |02:40:00      |0–6h      |3     |\n",
      "|rq6drw6h|Benício Miguel    |49            |40–59       |2025-06-01    |02:15:00      |0–6h      |4     |\n",
      "|t5m2wbne|Orlando Costa     |63            |60+         |2025-06-01    |01:40:00      |0–6h      |5     |\n",
      "|trifvf5a|Aparecida Gomes   |73            |60+         |2025-06-01    |02:25:00      |0–6h      |5     |\n",
      "|917tsf4k|Marcelo Fernandes |14            |13–17       |2025-05-30    |02:00:00      |0–6h      |2     |\n",
      "|n2qi2ea3|Rodrigo Costa     |49            |40–59       |2025-05-30    |00:35:00      |0–6h      |4     |\n",
      "|5xw5ln6i|Maria Vitória     |6             |0–12        |2025-05-28    |01:00:00      |0–6h      |1     |\n",
      "|d7241w3y|Gabriela Valentina|17            |13–17       |2025-05-28    |01:50:00      |0–6h      |2     |\n",
      "|ro2gr5wf|Leonardo Henrique |47            |40–59       |2025-05-28    |01:30:00      |0–6h      |11    |\n",
      "|d3cjhyau|Thiago Luís       |13            |13–17       |2025-05-28    |01:40:00      |0–6h      |9     |\n",
      "|9h3vanw1|Lucas Gabriel     |14            |13–17       |2025-05-26    |00:20:00      |0–6h      |2     |\n",
      "|94sdw1qt|Beatriz Dias      |16            |13–17       |2025-05-29    |01:45:00      |0–6h      |2     |\n",
      "|q500p70w|Lara Lima         |44            |40–59       |2025-05-29    |04:30:00      |0–6h      |4     |\n",
      "|t2r8ugoj|Marcos Silva      |75            |60+         |2025-05-29    |01:45:00      |0–6h      |5     |\n",
      "|52ms24tg|Valentina Isabella|5             |0–12        |2025-05-20    |03:20:00      |0–6h      |1     |\n",
      "|i6t1g8w5|Alexandre Santos  |31            |18–39       |2025-05-20    |02:50:00      |0–6h      |3     |\n",
      "|pyzg3ms9|Heitor Almeida    |48            |40–59       |2025-05-20    |01:15:00      |0–6h      |4     |\n",
      "|0rfdcax5|Nina Cardoso      |10            |0–12        |2025-05-20    |04:10:00      |0–6h      |6     |\n",
      "|r6nfsefh|Davi Lucca        |47            |40–59       |2025-05-27    |02:10:00      |0–6h      |4     |\n",
      "|se3x6us8|Mariana Sophia    |46            |40–59       |2025-06-01    |01:35:00      |0–6h      |4     |\n",
      "|djn7ymfv|Ana Laura         |17            |13–17       |2025-05-30    |01:30:00      |0–6h      |2     |\n",
      "|imlv36mt|Thiago Oliveira   |40            |40–59       |2025-05-30    |01:50:00      |0–6h      |3     |\n",
      "|h5m2gmbn|Marcelo Rocha     |39            |18–39       |2025-05-30    |00:45:00      |0–6h      |3     |\n",
      "|fcgyva7u|Érica Vieira      |31            |18–39       |2025-05-30    |02:40:00      |0–6h      |3     |\n",
      "|np7jt52k|Amanda Pereira    |56            |40–59       |2025-05-30    |04:15:00      |0–6h      |4     |\n",
      "|r6nfsefh|Davi Lucca        |47            |40–59       |2025-05-30    |01:10:00      |0–6h      |4     |\n",
      "|lcfk6jkd|Vinícius Duarte   |47            |40–59       |2025-05-30    |01:45:00      |0–6h      |4     |\n",
      "|vbahif03|Ademir Rocha      |67            |60+         |2025-05-30    |00:20:00      |0–6h      |5     |\n",
      "|tjossf3f|Ursulina Prado    |75            |60+         |2025-05-30    |02:25:00      |0–6h      |5     |\n",
      "|1udia861|Gustavo Rocha     |6             |0–12        |2025-05-28    |02:25:00      |0–6h      |1     |\n",
      "|fa3fbsro|Carla Meireles    |38            |18–39       |2025-05-28    |00:10:00      |0–6h      |3     |\n",
      "|8jz897i1|Gustavo Rocha     |17            |13–17       |2025-05-26    |01:40:00      |0–6h      |2     |\n",
      "|ahymntsh|Giovanna Mendes   |15            |13–17       |2025-05-26    |00:15:00      |0–6h      |2     |\n",
      "|h5cmipk2|Patrícia Pereira  |27            |18–39       |2025-05-26    |03:10:00      |0–6h      |3     |\n",
      "|v4o72pqz|Madalena Campos   |63            |60+         |2025-05-26    |01:35:00      |0–6h      |5     |\n",
      "|mfcfs10z|Mariana Santana   |43            |40–59       |2025-05-26    |01:10:00      |0–6h      |9     |\n",
      "|9uk43yhg|Sophia Castro     |16            |13–17       |2025-05-29    |00:00:00      |0–6h      |2     |\n",
      "|egxcr7jz|Sabrina Lopes     |26            |18–39       |2025-05-29    |00:05:00      |0–6h      |3     |\n",
      "|ig5z68oz|Andréa Costa      |27            |18–39       |2025-05-29    |05:35:00      |0–6h      |3     |\n",
      "|ui1u0k29|Antônio Santos    |62            |60+         |2025-05-29    |01:50:00      |0–6h      |5     |\n",
      "|e22y29pc|Rafael Augusto    |18            |18–39       |2025-05-20    |00:00:00      |0–6h      |2     |\n",
      "|hbq9p3or|Lucas Carvalho    |39            |18–39       |2025-05-20    |00:20:00      |0–6h      |3     |\n",
      "|ro2gr5wf|Leonardo Henrique |47            |40–59       |2025-05-20    |02:55:00      |0–6h      |4     |\n",
      "|3drhn6wf|Arthur Gomes      |5             |0–12        |2025-05-20    |01:20:00      |0–6h      |8     |\n",
      "|8838bfwl|Lucas Pereira     |14            |13–17       |2025-05-27    |01:35:00      |0–6h      |2     |\n",
      "|ltfu0uy6|Marta Oliveira    |41            |40–59       |2025-05-27    |02:55:00      |0–6h      |4     |\n",
      "|yptja7w3|Sueli José        |64            |60+         |2025-05-27    |00:10:00      |0–6h      |5     |\n",
      "|ylq9mac9|Queiroz Daniel    |68            |60+         |2025-05-27    |00:10:00      |0–6h      |5     |\n",
      "|z3q9mbuh|Maria Clara       |64            |60+         |2025-05-27    |02:10:00      |0–6h      |5     |\n",
      "|2rpnhzi3|Sophia Campos     |5             |0–12        |2025-06-01    |00:00:00      |0–6h      |1     |\n",
      "|5hypr6cv|Laura Helena      |9             |0–12        |2025-06-01    |13:25:00      |12–15h    |6     |\n",
      "|bcadxd2e|Gabriela Ribeiro  |17            |13–17       |2025-05-30    |00:00:00      |0–6h      |2     |\n",
      "|kiuykpk3|Isabela Souza     |31            |18–39       |2025-05-30    |00:55:00      |0–6h      |3     |\n",
      "|mn9pzhes|Larissa Barbosa   |40            |40–59       |2025-05-28    |01:25:00      |0–6h      |4     |\n",
      "|r6nfsefh|Davi Lucca        |47            |40–59       |2025-05-28    |01:30:00      |0–6h      |6     |\n",
      "|tbaf524e|Quitéria Santos   |63            |60+         |2025-05-26    |01:35:00      |0–6h      |5     |\n",
      "|y9lwgr9d|Ketty Sophia      |64            |60+         |2025-05-26    |03:10:00      |0–6h      |5     |\n",
      "|fa3fbsro|Carla Meireles    |38            |18–39       |2025-05-29    |01:25:00      |0–6h      |3     |\n",
      "|jmfvw8wz|Antônio Brito     |35            |18–39       |2025-05-29    |03:40:00      |0–6h      |3     |\n",
      "|6e2mu6xn|Vicente Gabriel   |7             |0–12        |2025-05-20    |01:10:00      |0–6h      |1     |\n",
      "|equ5g979|Kelly Regina      |26            |18–39       |2025-05-20    |02:10:00      |0–6h      |3     |\n",
      "|o09v8y1m|Paulo Lima        |45            |40–59       |2025-05-20    |00:05:00      |0–6h      |4     |\n",
      "|55ltcupc|Clara Liz         |9             |0–12        |2025-05-27    |02:05:00      |0–6h      |1     |\n",
      "|8nd3of0o|Bruna Oliveira    |17            |13–17       |2025-05-27    |04:50:00      |0–6h      |2     |\n",
      "|qc38k5ne|Vicente Nogueira  |46            |40–59       |2025-05-27    |00:35:00      |0–6h      |4     |\n",
      "|y7mkcps1|Jaime Miguel      |70            |60+         |2025-05-27    |00:30:00      |0–6h      |5     |\n",
      "|0kufs4qj|Luiza Amaral      |7             |0–12        |2025-05-27    |01:35:00      |0–6h      |11    |\n",
      "|a5yd28su|Rafael Martins    |15            |13–17       |2025-06-01    |02:00:00      |0–6h      |2     |\n",
      "|mfcfs10z|Mariana Santana   |43            |40–59       |2025-06-01    |01:05:00      |0–6h      |4     |\n",
      "|78avmqq5|Juliana Costa     |16            |13–17       |2025-06-01    |00:05:00      |0–6h      |8     |\n",
      "|jmfvw8wz|Antônio Brito     |35            |18–39       |2025-05-30    |02:00:00      |0–6h      |3     |\n",
      "|jk88r7mu|Sérgio Farias     |37            |18–39       |2025-05-30    |02:00:00      |0–6h      |3     |\n",
      "|oe0a44qz|Flávia Souza      |51            |40–59       |2025-05-30    |02:40:00      |0–6h      |4     |\n",
      "|dj14afu8|Mateus Henrique   |13            |13–17       |2025-05-28    |02:25:00      |0–6h      |2     |\n",
      "|hculv83o|Amanda Nogueira   |34            |18–39       |2025-05-28    |01:35:00      |0–6h      |3     |\n",
      "|snp0jqer|Arthur Daniel     |48            |40–59       |2025-05-28    |03:40:00      |0–6h      |4     |\n",
      "|9uk43yhg|Sophia Castro     |16            |13–17       |2025-05-26    |07:10:00      |6–9h      |2     |\n",
      "|f51wg06k|Aline Martins     |35            |18–39       |2025-05-26    |00:00:00      |0–6h      |3     |\n",
      "|hculv83o|Amanda Nogueira   |34            |18–39       |2025-05-26    |04:05:00      |0–6h      |3     |\n",
      "|1whumk7u|Leonardo Lima     |5             |0–12        |2025-05-29    |01:50:00      |0–6h      |1     |\n",
      "|rmhirya0|Lívia Gabriele    |59            |40–59       |2025-05-29    |01:55:00      |0–6h      |4     |\n",
      "|4w7j7px1|Isadora Sofia     |8             |0–12        |2025-05-20    |02:55:00      |0–6h      |1     |\n",
      "|cxmi38q8|Leonardo Emanuel  |17            |13–17       |2025-05-20    |02:20:00      |0–6h      |2     |\n",
      "|d8p8nj5p|Luiz Fernando     |14            |13–17       |2025-05-27    |05:00:00      |0–6h      |2     |\n",
      "|j59x8wen|Douglas Santos    |25            |18–39       |2025-05-27    |03:45:00      |0–6h      |3     |\n",
      "|846onaqz|Vitória Gomes     |15            |13–17       |2025-05-27    |01:15:00      |0–6h      |6     |\n",
      "|bvkfr8ls|Lucas Gabriel     |13            |13–17       |2025-06-01    |05:30:00      |0–6h      |2     |\n",
      "|ex8awzfz|Wesley Fernandes  |31            |18–39       |2025-06-01    |02:55:00      |0–6h      |3     |\n",
      "|oy6fj0on|Regina Dias       |51            |40–59       |2025-06-01    |03:20:00      |0–6h      |4     |\n",
      "|j59x8wen|Douglas Santos    |25            |18–39       |2025-05-30    |06:10:00      |6–9h      |3     |\n",
      "|i0fow7y2|Vitor Hugo        |37            |18–39       |2025-05-30    |00:20:00      |0–6h      |3     |\n",
      "|pwpryj15|Arthur Gomes      |45            |40–59       |2025-05-30    |00:45:00      |0–6h      |4     |\n",
      "|xc7rwkmm|Leda Samuel       |64            |60+         |2025-05-28    |01:25:00      |0–6h      |5     |\n",
      "|0s91mlso|Pietra Moraes     |6             |0–12        |2025-05-26    |00:05:00      |0–6h      |1     |\n",
      "|xfybq6xe|Quitéria Beatriz  |71            |60+         |2025-05-26    |00:20:00      |0–6h      |5     |\n",
      "|5xw5ln6i|Maria Vitória     |6             |0–12        |2025-05-29    |00:30:00      |0–6h      |1     |\n",
      "|1vkadgxu|Beatriz Dias      |11            |0–12        |2025-05-29    |00:35:00      |0–6h      |1     |\n",
      "+--------+------------------+--------------+------------+--------------+--------------+----------+------+\n",
      "only showing top 120 rows\n",
      "\n",
      "\n",
      "Salvando DataFrame de biometria para: s3a://bucket-trusted-upa-connect-mateus/biometria_paciente.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/13 20:08:08 WARN AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.\n",
      "25/06/13 20:08:09 WARN AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame de biometria salvo com sucesso no S3.\n",
      "\n",
      "Baixando credenciais do S3: s3://bucket-trusted-upa-connect-mateus/credenciais.json para /tmp/credenciais.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/boto3/compat.py:82: PythonDeprecationWarning: Boto3 will no longer support Python 3.7 starting December 13, 2023. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.8 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credenciais baixadas com sucesso.\n",
      "\n",
      "Enviando DataFrame de biometria para a aba 'BiometriaPaciente'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Spark de biometria convertido para Pandas com sucesso.\n",
      "Aba 'BiometriaPaciente' encontrada e limpa.\n",
      "Dados do DataFrame de biometria enviados com sucesso para a aba 'BiometriaPaciente'.\n",
      "Arquivo de credenciais temporário '/tmp/credenciais.json' removido.\n",
      "\n",
      "Sessão Spark parada.\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, lit, to_date, to_timestamp, hour, floor, datediff, current_date, min, lower, trim, count, udf, date_format\n",
    "from pyspark.sql.types import StringType, DateType, TimestampType, IntegerType\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Função para instalar pacotes\n",
    "def install_package(package_with_version):\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_with_version])\n",
    "        print(f\"'{package_with_version}' instalado com sucesso.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao instalar '{package_with_version}': {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "# Instalar as bibliotecas necessárias com versões compatíveis com Python 3.7\n",
    "# 'Literal' foi introduzido no Python 3.8. Versões mais recentes de gspread/google-auth-oauthlib\n",
    "# podem depender dele. Estamos fixando versões mais antigas.\n",
    "install_package(\"pandas\")\n",
    "install_package(\"gspread==3.6.0\") # Versão compatível com Python 3.7\n",
    "install_package(\"google-auth-oauthlib==0.4.6\") # Versão compatível com Python 3.7\n",
    "install_package(\"boto3\")\n",
    "# --- Fim da seção de instalação de bibliotecas ---\n",
    "\n",
    "# --- Importação de bibliotecas ---\n",
    "import os\n",
    "import pandas as pd\n",
    "import gspread\n",
    "from google.oauth2.service_account import Credentials\n",
    "import boto3\n",
    "import datetime # Importado para verificar o tipo datetime.date\n",
    "        \n",
    "\n",
    "# Configurações do Spark\n",
    "conf = SparkConf()\n",
    "conf.set('spark.jars.packages', 'org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.11.901')\n",
    "conf.set('spark.hadoop.fs.s3a.aws.credentials.provider', 'com.amazonaws.auth.InstanceProfileCredentialsProvider')\n",
    "\n",
    "# Criar sessão Spark\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "# Lista de arquivos CSV a serem lidos\n",
    "csv_files = [\n",
    "    'dados_2025_06_02.csv',\n",
    "    'dados_2025_05_27.csv',\n",
    "    'dados_2025_05_28.csv',\n",
    "    'dados_2025_05_29.csv',\n",
    "    'dados_2025_05_30.csv',\n",
    "    'dados_2025_05_31.csv',\n",
    "    'dados_2025_06_01.csv',\n",
    "    'dados_2025_05_20.csv',\n",
    "    'dados_2025_05_21.csv',\n",
    "    'dados_2025_05_22.csv',\n",
    "    'dados_2025_05_23.csv',\n",
    "    'dados_2025_05_24.csv',\n",
    "    'dados_2025_05_25.csv',\n",
    "    'dados_2025_05_26.csv'\n",
    "]\n",
    "\n",
    "# Prefixo do caminho S3\n",
    "s3_prefix = 's3a://bucket-raw-upa-connect-mateus/'\n",
    "\n",
    "# Criar a lista completa de caminhos S3\n",
    "s3_paths = [s3_prefix + file for file in csv_files]\n",
    "\n",
    "# Ler os CSVs necessários a partir da lista de caminhos\n",
    "TabelaCompleta = spark.read.option('delimiter', ',') \\\n",
    "                             .option('header', 'true') \\\n",
    "                             .option('nullValue', 'null') \\\n",
    "                             .csv(s3_paths) # Agora lê múltiplos arquivos\n",
    "\n",
    "paciente_df = spark.read.option('delimiter', ',') \\\n",
    "                         .option('header', 'true') \\\n",
    "                         .csv('s3a://bucket-trusted-upa-connect-mateus/paciente.csv')\n",
    "\n",
    "print(\"--- DataFrames Iniciais ---\")\n",
    "print(\"Schema de TabelaCompleta:\")\n",
    "TabelaCompleta.printSchema()\n",
    "print(\"Amostra de TabelaCompleta:\")\n",
    "TabelaCompleta.show(5, truncate=False)\n",
    "\n",
    "print(\"\\nSchema de paciente_df:\")\n",
    "paciente_df.printSchema()\n",
    "print(\"Amostra de paciente_df:\")\n",
    "paciente_df.show(5, truncate=False)\n",
    "\n",
    "### **Processamento para o Sensor 5 (Biometria)**\n",
    "\n",
    "print(\"\\n--- Processamento para o Sensor 5 (Biometria) ---\")\n",
    "\n",
    "# 1. Filtrar pelo sensor 5 e remover valores nulos em 'valor'\n",
    "df_biometria = TabelaCompleta.filter(col(\"fk_sensor\") == 5) \\\n",
    "                             .filter(col('valor').isNotNull())\n",
    "\n",
    "print(\"\\nDataFrame df_biometria após filtro e remoção de nulos:\")\n",
    "df_biometria.show(5, truncate=False)\n",
    "\n",
    "# 2. Converter 'valor' para StringType (biometria), 'fk_upa' para IntegerType e 'data_hora' para Timestamp\n",
    "# Normalizar a coluna 'valor' (biometria) para join\n",
    "df_biometria = df_biometria.withColumn('valor', lower(trim(col('valor'))).cast(StringType())) \\\n",
    "                           .withColumn('fk_upa', col('fk_upa').cast(IntegerType())) \\\n",
    "                           .withColumn('data_hora', to_timestamp(col('data_hora'))) # Converter para Timestamp\n",
    "\n",
    "print(\"\\nDataFrame df_biometria após cast e normalização de 'valor':\")\n",
    "df_biometria.show(5, truncate=False)\n",
    "df_biometria.printSchema()\n",
    "\n",
    "\n",
    "# 3. Agrupar por biometria e dia, pegando a primeira ocorrência do dia e o fk_upa\n",
    "df_biometria_agrupado = df_biometria.groupBy(\n",
    "    'valor',\n",
    "    to_date(col('data_hora')).alias('data_biometria') # Renomeado para data_biometria\n",
    ").agg(\n",
    "    min(col('data_hora')).alias('primeira_data_hora_dia'),\n",
    "    min(col('fk_upa')).alias('fk_upa') # Manter o fk_upa do registro original\n",
    ").orderBy('data_biometria', 'valor') # Ordenar por data_biometria\n",
    "\n",
    "print(\"\\nDataFrame df_biometria_agrupado:\")\n",
    "df_biometria_agrupado.show(5, truncate=False)\n",
    "df_biometria_agrupado.printSchema()\n",
    "\n",
    "# REMOVIDA: UDF para decodificar a biometria, pois o CSV já está arrumado.\n",
    "\n",
    "# 4. Juntar com paciente_df APENAS para obter a data_nascimento\n",
    "# Normalizar a coluna 'biometria' em paciente_df para join (agora sem decodificação)\n",
    "paciente_df_normalized = paciente_df.withColumn('biometria_join', lower(trim(col('biometria'))).cast(StringType()))\n",
    "\n",
    "# Adicionado para visualizar a biometria normalizada no paciente_df_normalized\n",
    "print(\"\\nDataFrame paciente_df_normalized com 'biometria_join' (após normalização):\")\n",
    "# Removido 'biometria_cleaned' do select, pois a UDF foi removida\n",
    "paciente_df_normalized.select('biometria', 'biometria_join', 'nome', 'data_nascimento').show(10, truncate=False)\n",
    "\n",
    "\n",
    "df_biometria_final = df_biometria_agrupado.join(\n",
    "    paciente_df_normalized.select('biometria_join', 'data_nascimento', 'nome', 'cpf'), # Selecionar 'nome'\n",
    "    df_biometria_agrupado.valor == paciente_df_normalized.biometria_join,\n",
    "    \"left_outer\" # Usar left_outer para manter todas as biometrias, mesmo que não encontre paciente\n",
    ").withColumnRenamed(\"nome\", \"nome_paciente\") \\\n",
    " .withColumnRenamed(\"cpf\", \"cpf_paciente\") \\\n",
    " .drop(\"biometria_join\") # A coluna biometria_join não é mais necessária após o join\n",
    "\n",
    "print(\"\\nDataFrame df_biometria_final após o JOIN (antes de calcular idade):\")\n",
    "df_biometria_final.show(10, truncate=False) # Mostrar mais linhas para ver os nulos\n",
    "df_biometria_final.printSchema()\n",
    "\n",
    "# Verificar contagem de nulos após o join\n",
    "print(\"\\nContagem de nulos em colunas chave após o JOIN:\")\n",
    "df_biometria_final.select(\n",
    "    count(when(col(\"nome_paciente\").isNull(), 1)).alias(\"nulos_nome_paciente\"),\n",
    "    count(when(col(\"data_nascimento\").isNull(), 1)).alias(\"nulos_data_nascimento\"),\n",
    "    count(when(col(\"cpf_paciente\").isNull(), 1)).alias(\"nulos_cpf_paciente\")\n",
    ").show()\n",
    "\n",
    "# 5. Calcular Idade e Faixa Etária\n",
    "# Assegurar que 'data_nascimento' é tipo Data.\n",
    "# Tentaremos múltiplos formatos de data. Se nenhum funcionar, resultará em NULL.\n",
    "df_biometria_final = df_biometria_final.withColumn(\n",
    "    \"data_nascimento_dt\",\n",
    "    when(to_date(col(\"data_nascimento\"), \"yyyy-MM-dd\").isNotNull(), to_date(col(\"data_nascimento\"), \"yyyy-MM-dd\"))\n",
    "    .when(to_date(col(\"data_nascimento\"), \"dd/MM/yyyy\").isNotNull(), to_date(col(\"data_nascimento\"), \"dd/MM/yyyy\"))\n",
    "    .when(to_date(col(\"data_nascimento\"), \"MM/dd/yyyy\").isNotNull(), to_date(col(\"data_nascimento\"), \"MM/dd/yyyy\"))\n",
    "    .otherwise(lit(None).cast(DateType())) # Caso nenhum formato corresponda\n",
    ")\n",
    "df_biometria_final = df_biometria_final.withColumn(\n",
    "    \"IdadeCorrigida\", floor(datediff(current_date(), col(\"data_nascimento_dt\")) / 365.25)\n",
    ")\n",
    "# Renomear IdadeCorrigida para idade_paciente\n",
    "df_biometria_final = df_biometria_final.withColumnRenamed(\"IdadeCorrigida\", \"idade_paciente\")\n",
    "\n",
    "\n",
    "df_biometria_final = df_biometria_final.withColumn(\"Faixa_Etaria\",\n",
    "    when((col(\"idade_paciente\") >= 0) & (col(\"idade_paciente\") <= 12), \"0–12\") # Usar idade_paciente\n",
    "    .when((col(\"idade_paciente\") >= 13) & (col(\"idade_paciente\") <= 17), \"13–17\") # Usar idade_paciente\n",
    "    .when((col(\"idade_paciente\") >= 18) & (col(\"idade_paciente\") <= 39), \"18–39\") # Usar idade_paciente\n",
    "    .when((col(\"idade_paciente\") >= 40) & (col(\"idade_paciente\") <= 59), \"40–59\") # Usar idade_paciente\n",
    "    .otherwise(\"60+\"))\n",
    "\n",
    "# 6. Criar Faixa de Horários\n",
    "df_biometria_final = df_biometria_final.withColumn(\"Hora\", hour(col(\"primeira_data_hora_dia\")))\n",
    "df_biometria_final = df_biometria_final.withColumn(\"Faixa_Hora\",\n",
    "    when((col(\"Hora\") >= 0) & (col(\"Hora\") < 6), \"0–6h\")\n",
    "    .when((col(\"Hora\") >= 6) & (col(\"Hora\") < 9), \"6–9h\")\n",
    "    .when((col(\"Hora\") >= 9) & (col(\"Hora\") < 12), \"9–12h\")\n",
    "    .when((col(\"Hora\") >= 12) & (col(\"Hora\") < 15), \"12–15h\")\n",
    "    .when((col(\"Hora\") >= 15) & (col(\"Hora\") < 18), \"15–18h\")\n",
    "    .when((col(\"Hora\") >= 18) & (col(\"Hora\") < 21), \"18–21h\")\n",
    "    .otherwise(\"21–24h\"))\n",
    "\n",
    "# 7. Selecionar e ordenar as colunas finais\n",
    "colunas_biometria_ordenadas = [\n",
    "    'valor',\n",
    "    'nome_paciente',\n",
    "    'idade_paciente', # RENOMEADA\n",
    "    'Faixa_Etaria',\n",
    "    'data_biometria', # RENOMEADA E REORDENADA\n",
    "    date_format(col('primeira_data_hora_dia'), 'HH:mm:ss').alias('hora_biometria'), # Apenas a hora, minuto e segundo, e RENOMEADA\n",
    "    'Faixa_Hora',\n",
    "    'fk_upa'\n",
    "]\n",
    "\n",
    "df_biometria_final = df_biometria_final.select(colunas_biometria_ordenadas)\n",
    "\n",
    "print(\"\\n--- DataFrame Final de Biometria ---\")\n",
    "df_biometria_final.show(120, truncate=False)\n",
    "\n",
    "# Salvar o DataFrame de biometria em CSV no S3\n",
    "output_path_biometria = 's3a://bucket-trusted-upa-connect-mateus/biometria_paciente.csv'\n",
    "print(f\"\\nSalvando DataFrame de biometria para: {output_path_biometria}\")\n",
    "df_biometria_final.coalesce(1) \\\n",
    "                  .write \\\n",
    "                  .option('header', 'true') \\\n",
    "                  .mode('overwrite') \\\n",
    "                  .csv(output_path_biometria)\n",
    "print(\"DataFrame de biometria salvo com sucesso no S3.\")\n",
    "\n",
    "### **Enviar DataFrame para Google Sheets**\n",
    "\n",
    "# === CONFIGURAÇÕES PARA O GOOGLE SHEETS ===\n",
    "GOOGLE_SHEET_ID = '1i6BfuZXPOcTp6BFAiVkpktOBym0HtakZacUKfDzu1zI' # Use o ID da sua planilha\n",
    "S3_BUCKET_CREDENTIALS = 'bucket-trusted-upa-connect-mateus'\n",
    "S3_KEY_CREDENTIALS = 'credenciais.json'\n",
    "LOCAL_CREDENTIALS_PATH = '/tmp/credenciais.json'\n",
    "\n",
    "# === AUTENTICAÇÃO GOOGLE ===\n",
    "print(f\"\\nBaixando credenciais do S3: s3://{S3_BUCKET_CREDENTIALS}/{S3_KEY_CREDENTIALS} para {LOCAL_CREDENTIALS_PATH}...\")\n",
    "s3 = boto3.client('s3')\n",
    "try:\n",
    "    s3.download_file(S3_BUCKET_CREDENTIALS, S3_KEY_CREDENTIALS, LOCAL_CREDENTIALS_PATH)\n",
    "    print(\"Credenciais baixadas com sucesso.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao baixar credenciais do S3: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "scopes = [\"https://www.googleapis.com/auth/spreadsheets\", \"https://www.googleapis.com/auth/drive\"]\n",
    "credenciais = Credentials.from_service_account_file(LOCAL_CREDENTIALS_PATH, scopes=scopes)\n",
    "cliente = gspread.authorize(credenciais)\n",
    "planilha = cliente.open_by_key(GOOGLE_SHEET_ID)\n",
    "\n",
    "# === ENVIA O DATAFRAME DE BIOMETRIA PARA A NOVA ABA \"BiometriaPaciente\" ===\n",
    "NOME_ABA_BIOMETRIA_PACIENTE = \"BiometriaPaciente\"\n",
    "print(f\"\\nEnviando DataFrame de biometria para a aba '{NOME_ABA_BIOMETRIA_PACIENTE}'...\")\n",
    "\n",
    "# Converter Spark DataFrame df_biometria_final para Pandas DataFrame\n",
    "try:\n",
    "    df_biometria_pandas = df_biometria_final.toPandas()\n",
    "    print(\"DataFrame Spark de biometria convertido para Pandas com sucesso.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao converter Spark DataFrame de biometria para Pandas: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Ajustar tipagem das colunas para o Google Sheets\n",
    "# Coluna 'data_biometria': assegurar que é string DD/MM/YYYY\n",
    "if 'data_biometria' in df_biometria_pandas.columns:\n",
    "    # Verifica se a coluna ainda é do tipo datetime.date (ou similar) e a formata.\n",
    "    # Caso contrário, se já for string, assume que está ok e apenas preenche nulos.\n",
    "    if pd.api.types.is_object_dtype(df_biometria_pandas['data_biometria']):\n",
    "        df_biometria_pandas['data_biometria'] = df_biometria_pandas['data_biometria'].apply(\n",
    "            lambda x: x.strftime('%d/%m/%Y') if isinstance(x, (datetime.date, datetime.datetime)) else x\n",
    "        )\n",
    "    df_biometria_pandas['data_biometria'] = df_biometria_pandas['data_biometria'].fillna('')\n",
    "\n",
    "\n",
    "# Coluna 'hora_biometria': (já vem como string 'HH:mm:ss' do Spark)\n",
    "if 'hora_biometria' in df_biometria_pandas.columns:\n",
    "    df_biometria_pandas['hora_biometria'] = df_biometria_pandas['hora_biometria'].fillna('')\n",
    "\n",
    "# Coluna 'data_nascimento' não está mais no df_biometria_final, então a lógica para ela foi removida.\n",
    "# A coluna 'IdadeCorrigida' foi renomeada para 'idade_paciente' e já é numérica, não necessita de tratamento especial aqui.\n",
    "\n",
    "dados_biometria = [df_biometria_pandas.columns.tolist()] + df_biometria_pandas.values.tolist()\n",
    "\n",
    "try:\n",
    "    aba_biometria = planilha.worksheet(NOME_ABA_BIOMETRIA_PACIENTE)\n",
    "    aba_biometria.clear()\n",
    "    print(f\"Aba '{NOME_ABA_BIOMETRIA_PACIENTE}' encontrada e limpa.\")\n",
    "except gspread.exceptions.WorksheetNotFound:\n",
    "    aba_biometria = planilha.add_worksheet(title=NOME_ABA_BIOMETRIA_PACIENTE, rows=str(len(dados_biometria) + 100), cols=str(len(df_biometria_pandas.columns) + 10))\n",
    "    print(f\"Aba '{NOME_ABA_BIOMETRIA_PACIENTE}' criada.\")\n",
    "\n",
    "try:\n",
    "    aba_biometria.update(dados_biometria)\n",
    "    print(f\"Dados do DataFrame de biometria enviados com sucesso para a aba '{NOME_ABA_BIOMETRIA_PACIENTE}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao atualizar a aba do Google Sheets com dados de biometria: {e}\")\n",
    "\n",
    "# Opcional: Remover o arquivo de credenciais temporário\n",
    "if os.path.exists(LOCAL_CREDENTIALS_PATH):\n",
    "    os.remove(LOCAL_CREDENTIALS_PATH)\n",
    "    print(f\"Arquivo de credenciais temporário '{LOCAL_CREDENTIALS_PATH}' removido.\")\n",
    "\n",
    "# Parar a sessão Spark\n",
    "spark.stop()\n",
    "print(\"\\nSessão Spark parada.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
