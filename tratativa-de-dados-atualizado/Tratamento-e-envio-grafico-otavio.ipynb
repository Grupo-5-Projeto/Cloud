{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ada5fb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.7/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      "com.amazonaws#aws-java-sdk-bundle added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-3ba97ddf-ba59-4f34-a232-c223e89ff3b0;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.4 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.12.262 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      ":: resolution report :: resolve 604ms :: artifacts dl 14ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.12.262 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.4 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.901 by [com.amazonaws#aws-java-sdk-bundle;1.12.262] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   4   |   0   |   0   |   1   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-3ba97ddf-ba59-4f34-a232-c223e89ff3b0\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/15ms)\n",
      "25/06/16 23:36:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "/usr/local/lib/python3.7/site-packages/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n",
      "25/06/16 23:36:46 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+---------+--------------+-----------+------+\n",
      "|          data_hora|              valor|fk_sensor|fk_unid_medida|fk_paciente|fk_upa|\n",
      "+-------------------+-------------------+---------+--------------+-----------+------+\n",
      "|2025-06-11T00:05:00|                208|        1|          null|       null|     1|\n",
      "|2025-06-11T00:10:00|                 30|        1|          null|       null|     1|\n",
      "|2025-06-11T00:15:00|                160|        1|          null|       null|     1|\n",
      "|2025-06-11T00:20:00|                 10|        1|          null|       null|     1|\n",
      "|2025-06-11T00:25:00|                 11|        1|          null|       null|     1|\n",
      "|2025-06-11T00:30:00|                 12|        1|          null|       null|     1|\n",
      "|2025-06-11T00:35:00|                 11|        1|          null|       null|     1|\n",
      "|2025-06-11T00:40:00|                 13|        1|          null|       null|     1|\n",
      "|2025-06-11T00:45:00|  431.8561507820244|        1|          null|       null|     1|\n",
      "|2025-06-11T00:50:00|                 11|        1|          null|       null|     1|\n",
      "|2025-06-11T00:55:00|                 11|        1|          null|       null|     1|\n",
      "|2025-06-11T01:00:00| 0.9281383962193015|        1|          null|       null|     1|\n",
      "|2025-06-11T01:05:00|                 43|        1|          null|       null|     1|\n",
      "|2025-06-11T01:10:00|                  9|        1|          null|       null|     1|\n",
      "|2025-06-11T01:15:00|-3.5980943400431444|        1|          null|       null|     1|\n",
      "|2025-06-11T01:20:00| -5.040626662106107|        1|          null|       null|     1|\n",
      "|2025-06-11T01:25:00|                 12|        1|          null|       null|     1|\n",
      "|2025-06-11T01:30:00|                 10|        1|          null|       null|     1|\n",
      "|2025-06-11T01:35:00|                 10|        1|          null|       null|     1|\n",
      "|2025-06-11T01:40:00|                 10|        1|          null|       null|     1|\n",
      "+-------------------+-------------------+---------+--------------+-----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:=======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas: 783355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg, sum as sum_, first, round, min, when, lit, to_date, to_timestamp, date_format\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType, DateType, TimestampType\n",
    "\n",
    "# Configurações do Spark\n",
    "conf = SparkConf()\n",
    "conf.set('spark.jars.packages', 'org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.11.901')\n",
    "conf.set('spark.hadoop.fs.s3a.aws.credentials.provider', 'com.amazonaws.auth.InstanceProfileCredentialsProvider')\n",
    "\n",
    "# Criar sessão Spark\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "# # Ler o CSV, já tratando \"NULL\" como valor nulo\n",
    "# TabelaCompleta = spark.read.option('delimiter', ',') \\\n",
    "#               .option('header', 'true') \\\n",
    "#               .option('nullValue', 'null') \\\n",
    "#               .csv('s3a://bucket-raw-upa-connect-1/tabela_historico_sensor1.csv')\n",
    "\n",
    "# Lista de arquivos CSV a serem lidos\n",
    "csv_files = [\n",
    "    'dados_2025_06_09.csv',\n",
    "    'dados_2025_06_10.csv',\n",
    "    'dados_2025_06_11.csv',\n",
    "    'dados_2025_06_12.csv',\n",
    "    'dados_2025_06_13.csv'\n",
    "]\n",
    "\n",
    "# Prefixo do caminho S3\n",
    "s3_prefix = 's3a://bucket-raw-upa-connect-1/'\n",
    "\n",
    "# Criar a lista completa de caminhos S3\n",
    "s3_paths = [s3_prefix + file for file in csv_files]\n",
    "\n",
    "# Ler os CSVs necessários a partir da lista de caminhos\n",
    "TabelaCompleta = spark.read.option('delimiter', ',') \\\n",
    "                             .option('header', 'true') \\\n",
    "                             .option('nullValue', 'null') \\\n",
    "                             .csv(s3_paths) # Agora lê múltiplos arquivos\n",
    "\n",
    "\n",
    "# Ler o CSV, já tratando \"NULL\" como valor nulo\n",
    "upa_df = spark.read.option('delimiter', ',') \\\n",
    "              .option('header', 'true') \\\n",
    "              .csv('s3a://bucket-trusted-upa-connect-1/upa.csv')\n",
    "\n",
    "paciente_df = spark.read.option('delimiter', ',') \\\n",
    "              .option('header', 'true') \\\n",
    "              .csv('s3a://bucket-trusted-upa-connect-1/paciente.csv')\n",
    "\n",
    "sensor_df = spark.read.option('delimiter', ',') \\\n",
    "              .option('header', 'true') \\\n",
    "              .csv('s3a://bucket-trusted-upa-connect-1/sensor.csv')\n",
    "\n",
    "\n",
    "unidadeDeMedida_df = spark.read.option('delimiter', ',') \\\n",
    "              .option('header', 'true') \\\n",
    "              .csv('s3a://bucket-trusted-upa-connect-1/UnidadeDeMedida.csv')\n",
    "\n",
    "# Converter 'valor' para DoubleType e 'fk_upa' para IntegerType\n",
    "# a = a.withColumn('valor', col('valor').cast(DoubleType())) \\\n",
    "#      .withColumn('fk_paciente', col('fk_paciente').cast(IntegerType()))\n",
    "\n",
    "TabelaCompleta.show()\n",
    "# Conta as linhas\n",
    "num_linhas = TabelaCompleta.count()\n",
    "\n",
    "# Imprime o resultado\n",
    "print(f\"Número de linhas: {num_linhas}\")\n",
    "# upa_df.show()\n",
    "# paciente_df.show(170)\n",
    "# sensor_df.show()\n",
    "# unidadeDeMedida_df.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64702a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------------+-----------------+--------------------+--------------+------------+---------------+------+--------------------+\n",
      "|    nome_paciente|Oximetria_Media|Temperatura_Media|   Legenda Gravidade|Cor Indicativa|data_chegada|horario_chegada|fk_upa|         nome_da_upa|\n",
      "+-----------------+---------------+-----------------+--------------------+--------------+------------+---------------+------+--------------------+\n",
      "|        Ana Souza|           91.9|             38.2|     Atenção - Febre|       #FFD700|  2025-06-09|       00:20:00|     1|     UPA 21 DE JUNHO|\n",
      "|        Ana Souza|           90.5|             38.1|     Atenção - Febre|       #FFD700|  2025-06-10|       01:45:00|     1|     UPA 21 DE JUNHO|\n",
      "|        Ana Souza|           90.6|             38.0|Atenção - Oxigena...|       #32CD32|  2025-06-11|       04:00:00|     1|     UPA 21 DE JUNHO|\n",
      "|        Ana Souza|           91.8|             38.2|     Atenção - Febre|       #FFD700|  2025-06-12|       03:05:00|     1|     UPA 21 DE JUNHO|\n",
      "|        Ana Souza|           89.7|             38.1|     Atenção - Febre|       #FFD700|  2025-06-13|       01:20:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Bruno Oliveira|           89.2|             37.9|Atenção - Oxigena...|       #32CD32|  2025-06-09|       01:30:00|    11|       UPA JABAQUARA|\n",
      "|   Bruno Oliveira|           89.6|             38.3|     Atenção - Febre|       #FFD700|  2025-06-10|       01:20:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Bruno Oliveira|           91.9|             38.2|     Atenção - Febre|       #FFD700|  2025-06-11|       01:40:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Bruno Oliveira|           91.5|             38.1|     Atenção - Febre|       #FFD700|  2025-06-12|       01:20:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Bruno Oliveira|           89.6|             38.2|     Atenção - Febre|       #FFD700|  2025-06-13|       01:45:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Carlos Pereira|           89.2|             38.2|     Atenção - Febre|       #FFD700|  2025-06-09|       00:05:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Carlos Pereira|           90.8|             38.1|     Atenção - Febre|       #FFD700|  2025-06-10|       01:05:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Carlos Pereira|           90.8|             38.1|     Atenção - Febre|       #FFD700|  2025-06-11|       01:20:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Carlos Pereira|           89.3|             38.0|Atenção - Oxigena...|       #32CD32|  2025-06-12|       01:25:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Carlos Pereira|           89.9|             38.2|     Atenção - Febre|       #FFD700|  2025-06-13|       03:15:00|     1|     UPA 21 DE JUNHO|\n",
      "|     Daniela Lima|           90.1|             38.0|Atenção - Oxigena...|       #32CD32|  2025-06-09|       00:00:00|     1|     UPA 21 DE JUNHO|\n",
      "|     Daniela Lima|           91.9|             38.0|Atenção - Oxigena...|       #32CD32|  2025-06-10|       03:50:00|     1|     UPA 21 DE JUNHO|\n",
      "|     Daniela Lima|           87.8|             38.2|     Atenção - Febre|       #FFD700|  2025-06-11|       02:45:00|     1|     UPA 21 DE JUNHO|\n",
      "|     Daniela Lima|           90.9|             38.1|     Atenção - Febre|       #FFD700|  2025-06-12|       03:00:00|     1|     UPA 21 DE JUNHO|\n",
      "|     Daniela Lima|           90.4|             37.8|Atenção - Oxigena...|       #32CD32|  2025-06-13|       07:55:00|    12|          UPA JAÇANÃ|\n",
      "|   Eduardo Santos|           91.7|             38.2|     Atenção - Febre|       #FFD700|  2025-06-09|       00:25:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Eduardo Santos|           89.6|             38.1|     Atenção - Febre|       #FFD700|  2025-06-10|       01:00:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Eduardo Santos|           91.1|             38.1|     Atenção - Febre|       #FFD700|  2025-06-11|       01:05:00|    10|UPA IPIRANGA - AU...|\n",
      "|   Eduardo Santos|           91.6|             38.2|     Atenção - Febre|       #FFD700|  2025-06-12|       00:10:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Eduardo Santos|           91.4|             38.1|     Atenção - Febre|       #FFD700|  2025-06-13|       00:30:00|     1|     UPA 21 DE JUNHO|\n",
      "|     Luiza Amaral|           90.9|             38.0|Atenção - Oxigena...|       #32CD32|  2025-06-09|       00:55:00|     1|     UPA 21 DE JUNHO|\n",
      "|     Luiza Amaral|           91.1|             38.0|Atenção - Oxigena...|       #32CD32|  2025-06-10|       00:45:00|     1|     UPA 21 DE JUNHO|\n",
      "|     Luiza Amaral|           89.8|             38.1|     Atenção - Febre|       #FFD700|  2025-06-11|       01:15:00|     1|     UPA 21 DE JUNHO|\n",
      "|     Luiza Amaral|           91.2|             37.9|Atenção - Oxigena...|       #32CD32|  2025-06-12|       01:30:00|     1|     UPA 21 DE JUNHO|\n",
      "|     Luiza Amaral|           89.8|             37.9|Atenção - Oxigena...|       #32CD32|  2025-06-13|       00:40:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Miguel Tavares|           91.4|             38.1|     Atenção - Febre|       #FFD700|  2025-06-09|       02:25:00|    11|       UPA JABAQUARA|\n",
      "|   Miguel Tavares|           90.5|             38.2|     Atenção - Febre|       #FFD700|  2025-06-10|       02:25:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Miguel Tavares|           91.3|             38.1|     Atenção - Febre|       #FFD700|  2025-06-11|       00:00:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Miguel Tavares|           90.2|             38.0|Atenção - Oxigena...|       #32CD32|  2025-06-12|       02:25:00|    12|          UPA JAÇANÃ|\n",
      "|   Miguel Tavares|           89.6|             38.1|     Atenção - Febre|       #FFD700|  2025-06-13|       01:40:00|    17|     UPA JARDIM PERI|\n",
      "|     Nina Cardoso|           91.0|             38.2|     Atenção - Febre|       #FFD700|  2025-06-09|       03:30:00|     1|     UPA 21 DE JUNHO|\n",
      "|     Nina Cardoso|           91.5|             38.2|     Atenção - Febre|       #FFD700|  2025-06-10|       01:35:00|     1|     UPA 21 DE JUNHO|\n",
      "|     Nina Cardoso|           91.0|             38.2|     Atenção - Febre|       #FFD700|  2025-06-11|       01:25:00|    10|UPA IPIRANGA - AU...|\n",
      "|     Nina Cardoso|           89.2|             38.2|     Atenção - Febre|       #FFD700|  2025-06-12|       02:10:00|     1|     UPA 21 DE JUNHO|\n",
      "|     Nina Cardoso|           91.4|             38.0|Atenção - Oxigena...|       #32CD32|  2025-06-13|       05:25:00|     1|     UPA 21 DE JUNHO|\n",
      "|       Otávio Luz|           92.3|             38.0|Normal - Sem Alertas|       #008000|  2025-06-09|       02:20:00|     1|     UPA 21 DE JUNHO|\n",
      "|       Otávio Luz|           91.2|             37.9|Atenção - Oxigena...|       #32CD32|  2025-06-10|       05:05:00|     1|     UPA 21 DE JUNHO|\n",
      "|       Otávio Luz|           92.9|             38.0|Normal - Sem Alertas|       #008000|  2025-06-11|       04:25:00|    12|          UPA JAÇANÃ|\n",
      "|       Otávio Luz|           90.7|             38.0|Atenção - Oxigena...|       #32CD32|  2025-06-12|       03:50:00|    11|       UPA JABAQUARA|\n",
      "|       Otávio Luz|           90.6|             38.2|     Atenção - Febre|       #FFD700|  2025-06-13|       00:10:00|    12|          UPA JAÇANÃ|\n",
      "|    Pietra Moraes|           90.0|             38.1|     Atenção - Febre|       #FFD700|  2025-06-09|       02:05:00|     1|     UPA 21 DE JUNHO|\n",
      "|    Pietra Moraes|           91.9|             38.0|Atenção - Oxigena...|       #32CD32|  2025-06-10|       00:10:00|     1|     UPA 21 DE JUNHO|\n",
      "|    Pietra Moraes|           91.5|             38.0|Atenção - Oxigena...|       #32CD32|  2025-06-11|       00:05:00|     1|     UPA 21 DE JUNHO|\n",
      "|    Pietra Moraes|           89.3|             38.3|     Atenção - Febre|       #FFD700|  2025-06-12|       01:45:00|     1|     UPA 21 DE JUNHO|\n",
      "|    Pietra Moraes|           90.5|             38.2|     Atenção - Febre|       #FFD700|  2025-06-13|       00:20:00|     1|     UPA 21 DE JUNHO|\n",
      "|    Rebeca Soares|           90.9|             38.2|     Atenção - Febre|       #FFD700|  2025-06-09|       00:00:00|     1|     UPA 21 DE JUNHO|\n",
      "|    Rebeca Soares|           89.9|             37.8|Atenção - Oxigena...|       #32CD32|  2025-06-10|       00:00:00|     1|     UPA 21 DE JUNHO|\n",
      "|    Rebeca Soares|           90.6|             38.1|     Atenção - Febre|       #FFD700|  2025-06-11|       02:25:00|    14|UPA JARDIM ELISA ...|\n",
      "|    Rebeca Soares|           92.2|             38.1|     Atenção - Febre|       #FFD700|  2025-06-12|       00:45:00|     1|     UPA 21 DE JUNHO|\n",
      "|    Rebeca Soares|           89.6|             38.1|     Atenção - Febre|       #FFD700|  2025-06-13|       00:55:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Samuel Andrade|           89.9|             38.0|Atenção - Oxigena...|       #32CD32|  2025-06-09|       00:15:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Samuel Andrade|           90.7|             38.2|     Atenção - Febre|       #FFD700|  2025-06-10|       03:00:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Samuel Andrade|           93.0|             38.1|     Atenção - Febre|       #FFD700|  2025-06-11|       02:20:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Samuel Andrade|           90.4|             38.1|     Atenção - Febre|       #FFD700|  2025-06-12|       01:50:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Samuel Andrade|           88.3|             38.1|     Atenção - Febre|       #FFD700|  2025-06-13|       02:25:00|     1|     UPA 21 DE JUNHO|\n",
      "|    Tainá Ribeiro|           89.5|             38.0|Atenção - Oxigena...|       #32CD32|  2025-06-09|       02:30:00|     1|     UPA 21 DE JUNHO|\n",
      "|    Tainá Ribeiro|           89.3|             38.2|     Atenção - Febre|       #FFD700|  2025-06-10|       00:20:00|     1|     UPA 21 DE JUNHO|\n",
      "|    Tainá Ribeiro|           90.6|             37.9|Atenção - Oxigena...|       #32CD32|  2025-06-11|       02:25:00|     1|     UPA 21 DE JUNHO|\n",
      "|    Tainá Ribeiro|           92.4|             38.1|     Atenção - Febre|       #FFD700|  2025-06-12|       00:15:00|     1|     UPA 21 DE JUNHO|\n",
      "|    Tainá Ribeiro|           90.8|             38.3|     Atenção - Febre|       #FFD700|  2025-06-13|       00:50:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Ulisses Moraes|           90.0|             38.2|     Atenção - Febre|       #FFD700|  2025-06-09|       00:10:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Ulisses Moraes|           87.2|             38.4|     Atenção - Febre|       #FFD700|  2025-06-10|       00:35:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Ulisses Moraes|           91.7|             37.9|Atenção - Oxigena...|       #32CD32|  2025-06-11|       00:15:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Ulisses Moraes|           91.8|             38.1|     Atenção - Febre|       #FFD700|  2025-06-12|       00:00:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Ulisses Moraes|           90.2|             38.1|     Atenção - Febre|       #FFD700|  2025-06-13|       03:15:00|     1|     UPA 21 DE JUNHO|\n",
      "|    Vitória Alves|           92.5|             38.1|     Atenção - Febre|       #FFD700|  2025-06-09|       00:30:00|    11|       UPA JABAQUARA|\n",
      "|    Vitória Alves|           89.7|             37.8|Atenção - Oxigena...|       #32CD32|  2025-06-10|       00:55:00|     1|     UPA 21 DE JUNHO|\n",
      "|    Vitória Alves|           89.9|             38.1|     Atenção - Febre|       #FFD700|  2025-06-11|       01:35:00|     1|     UPA 21 DE JUNHO|\n",
      "|    Vitória Alves|           90.8|             38.1|     Atenção - Febre|       #FFD700|  2025-06-12|       03:35:00|     1|     UPA 21 DE JUNHO|\n",
      "|    Vitória Alves|           90.0|             38.1|     Atenção - Febre|       #FFD700|  2025-06-13|       00:20:00|     1|     UPA 21 DE JUNHO|\n",
      "|       João Neves|           88.9|             38.1|     Atenção - Febre|       #FFD700|  2025-06-09|       00:55:00|     1|     UPA 21 DE JUNHO|\n",
      "|       João Neves|           89.2|             38.3|     Atenção - Febre|       #FFD700|  2025-06-10|       00:05:00|     1|     UPA 21 DE JUNHO|\n",
      "|       João Neves|           92.3|             38.0|Normal - Sem Alertas|       #008000|  2025-06-11|       01:05:00|     1|     UPA 21 DE JUNHO|\n",
      "|       João Neves|           90.6|             38.2|     Atenção - Febre|       #FFD700|  2025-06-12|       00:05:00|     1|     UPA 21 DE JUNHO|\n",
      "|       João Neves|           88.2|             38.1|     Atenção - Febre|       #FFD700|  2025-06-13|       01:30:00|    10|UPA IPIRANGA - AU...|\n",
      "|      Sofia Costa|           90.8|             38.2|     Atenção - Febre|       #FFD700|  2025-06-09|       01:35:00|     1|     UPA 21 DE JUNHO|\n",
      "|      Sofia Costa|           89.1|             38.1|     Atenção - Febre|       #FFD700|  2025-06-10|       00:10:00|     1|     UPA 21 DE JUNHO|\n",
      "|      Sofia Costa|           91.2|             38.2|     Atenção - Febre|       #FFD700|  2025-06-11|       00:00:00|     1|     UPA 21 DE JUNHO|\n",
      "|      Sofia Costa|           90.3|             37.9|Atenção - Oxigena...|       #32CD32|  2025-06-12|       00:50:00|     1|     UPA 21 DE JUNHO|\n",
      "|      Sofia Costa|           91.4|             38.3|     Atenção - Febre|       #FFD700|  2025-06-13|       00:55:00|    10|UPA IPIRANGA - AU...|\n",
      "|   Pedro Henrique|           91.0|             38.3|     Atenção - Febre|       #FFD700|  2025-06-09|       00:35:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Pedro Henrique|           90.9|             38.0|Atenção - Oxigena...|       #32CD32|  2025-06-10|       00:45:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Pedro Henrique|           90.0|             38.1|     Atenção - Febre|       #FFD700|  2025-06-11|       01:30:00|    11|       UPA JABAQUARA|\n",
      "|   Pedro Henrique|           90.4|             38.1|     Atenção - Febre|       #FFD700|  2025-06-12|       00:30:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Pedro Henrique|           91.6|             38.0|Atenção - Oxigena...|       #32CD32|  2025-06-13|       01:25:00|     1|     UPA 21 DE JUNHO|\n",
      "|    Laura Almeida|           89.0|             38.2|     Atenção - Febre|       #FFD700|  2025-06-09|       01:20:00|     1|     UPA 21 DE JUNHO|\n",
      "|    Laura Almeida|           91.2|             38.0|Atenção - Oxigena...|       #32CD32|  2025-06-10|       01:00:00|     1|     UPA 21 DE JUNHO|\n",
      "|    Laura Almeida|           89.7|             38.0|Atenção - Oxigena...|       #32CD32|  2025-06-11|       05:05:00|     1|     UPA 21 DE JUNHO|\n",
      "|    Laura Almeida|           90.5|             38.2|     Atenção - Febre|       #FFD700|  2025-06-12|       00:40:00|     1|     UPA 21 DE JUNHO|\n",
      "|    Laura Almeida|           90.0|             38.3|     Atenção - Febre|       #FFD700|  2025-06-13|       01:15:00|     1|     UPA 21 DE JUNHO|\n",
      "|     Felipe Gomes|           90.7|             38.2|     Atenção - Febre|       #FFD700|  2025-06-09|       00:15:00|     1|     UPA 21 DE JUNHO|\n",
      "|     Felipe Gomes|           90.5|             38.1|     Atenção - Febre|       #FFD700|  2025-06-10|       00:05:00|    10|UPA IPIRANGA - AU...|\n",
      "|     Felipe Gomes|           92.3|             38.0|Normal - Sem Alertas|       #008000|  2025-06-11|       01:30:00|    13|   UPA JARDIM ANGELA|\n",
      "|     Felipe Gomes|           88.2|             38.2|     Atenção - Febre|       #FFD700|  2025-06-12|       01:35:00|     1|     UPA 21 DE JUNHO|\n",
      "|     Felipe Gomes|           91.5|             38.2|     Atenção - Febre|       #FFD700|  2025-06-13|       02:30:00|     1|     UPA 21 DE JUNHO|\n",
      "|Giovanna Carvalho|           90.4|             38.1|     Atenção - Febre|       #FFD700|  2025-06-09|       04:10:00|    10|UPA IPIRANGA - AU...|\n",
      "|Giovanna Carvalho|           89.9|             38.1|     Atenção - Febre|       #FFD700|  2025-06-10|       00:05:00|     1|     UPA 21 DE JUNHO|\n",
      "|Giovanna Carvalho|           89.9|             38.4|     Atenção - Febre|       #FFD700|  2025-06-11|       06:05:00|    10|UPA IPIRANGA - AU...|\n",
      "|Giovanna Carvalho|           91.7|             38.0|Atenção - Oxigena...|       #32CD32|  2025-06-12|       00:45:00|     1|     UPA 21 DE JUNHO|\n",
      "|Giovanna Carvalho|           90.4|             38.0|Atenção - Oxigena...|       #32CD32|  2025-06-13|       01:40:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Matheus Santos|           89.6|             38.0|Atenção - Oxigena...|       #32CD32|  2025-06-09|       01:55:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Matheus Santos|           91.6|             38.2|     Atenção - Febre|       #FFD700|  2025-06-10|       01:20:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Matheus Santos|           89.6|             38.3|     Atenção - Febre|       #FFD700|  2025-06-11|       00:20:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Matheus Santos|           90.8|             38.1|     Atenção - Febre|       #FFD700|  2025-06-12|       03:10:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Matheus Santos|           91.3|             38.0|Atenção - Oxigena...|       #32CD32|  2025-06-13|       00:45:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Larissa Mendes|           90.2|             38.2|     Atenção - Febre|       #FFD700|  2025-06-09|       00:30:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Larissa Mendes|           90.5|             38.0|Atenção - Oxigena...|       #32CD32|  2025-06-10|       00:15:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Larissa Mendes|           88.3|             37.9|Atenção - Oxigena...|       #32CD32|  2025-06-11|       03:40:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Larissa Mendes|           90.3|             38.1|     Atenção - Febre|       #FFD700|  2025-06-12|       00:40:00|     1|     UPA 21 DE JUNHO|\n",
      "|   Larissa Mendes|           90.8|             38.3|     Atenção - Febre|       #FFD700|  2025-06-13|       00:25:00|     1|     UPA 21 DE JUNHO|\n",
      "|    Gustavo Rocha|           91.2|             38.1|     Atenção - Febre|       #FFD700|  2025-06-09|       02:45:00|     1|     UPA 21 DE JUNHO|\n",
      "|    Gustavo Rocha|           89.9|             38.1|     Atenção - Febre|       #FFD700|  2025-06-10|       00:10:00|    10|UPA IPIRANGA - AU...|\n",
      "|    Gustavo Rocha|           90.5|             38.1|     Atenção - Febre|       #FFD700|  2025-06-11|       01:45:00|     1|     UPA 21 DE JUNHO|\n",
      "|    Gustavo Rocha|           89.3|             37.9|Atenção - Oxigena...|       #32CD32|  2025-06-12|       00:40:00|     1|     UPA 21 DE JUNHO|\n",
      "|    Gustavo Rocha|           89.1|             38.0|Atenção - Oxigena...|       #32CD32|  2025-06-13|       01:35:00|     1|     UPA 21 DE JUNHO|\n",
      "+-----------------+---------------+-----------------+--------------------+--------------+------------+---------------+------+--------------------+\n",
      "only showing top 120 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 1. Filtrar pelos sensores desejados e remover valores nulos em 'valor'\n",
    "df_filtrado_inicial = TabelaCompleta.filter(\n",
    "    (col(\"fk_sensor\") == 3) | (col(\"fk_sensor\") == 4)\n",
    ").filter(\n",
    "    col('valor').isNotNull()\n",
    ")\n",
    "\n",
    "# 2. Aplicar filtros de outlier específicos para cada sensor\n",
    "condicao_sensor_3 = (col('fk_sensor') == 3) & (col('valor') >= 0) & (col('valor') <= 100)\n",
    "condicao_sensor_4 = (col('fk_sensor') == 4) & (col('valor') >= 34) & (col('valor') <= 42)\n",
    "\n",
    "df_filtrado_final = df_filtrado_inicial.filter(\n",
    "    condicao_sensor_3 | condicao_sensor_4\n",
    ").orderBy(\"fk_paciente\")\n",
    "\n",
    "df_filtrado_final = df_filtrado_final.withColumn('valor', col('valor').cast(DoubleType())) \\\n",
    "     .withColumn('fk_paciente', col('fk_paciente').cast(IntegerType()))\n",
    "\n",
    "# df_filtrado_final.show()\n",
    "\n",
    "# --- ALTERAÇÃO PRINCIPAL AQUI: Agrupar por paciente E por dia ---\n",
    "df_resultado_final = df_filtrado_final.groupBy(\n",
    "    'fk_paciente',\n",
    "    to_date(col('data_hora')).alias('data_agrupamento_temporaria') # Coluna temporária para agrupar por dia\n",
    ").agg(\n",
    "    # Pega a menor data_hora para cada paciente por dia (pode ser ajustado para 'first' se preferir)\n",
    "    min(col('data_hora')).alias('data_hora'),\n",
    "    # Pega o primeiro fk_upa encontrado para cada paciente por dia (assumindo que fk_upa é o mesmo para o paciente)\n",
    "    min(col('fk_upa')).alias('fk_upa'),\n",
    "    # Média da Oximetria (fk_sensor = 3)\n",
    "    round(avg(when(col('fk_sensor') == 3, col('valor'))), 1).alias('Oximetria_Media'),\n",
    "    # Média da Temperatura (fk_sensor = 4)\n",
    "    round(avg(when(col('fk_sensor') == 4, col('valor'))), 1).alias('Temperatura_Media')\n",
    ").orderBy('fk_paciente', 'data_agrupamento_temporaria') # Ordena para facilitar a visualização por paciente e dia\n",
    "\n",
    "# df_resultado_final.show(120)\n",
    "\n",
    "# --- Adicionando as Colunas \"Legenda Gravidade\" e \"Cor Indicativa\" ---\n",
    "\n",
    "df_com_legenda = df_resultado_final.withColumn('Legenda Gravidade',\n",
    "    when(col('Oximetria_Media') < 87, 'Emergência - Oxigenação Crítica') # Mais grave, prioridade máxima\n",
    "    .when(col('Temperatura_Media') > 39.5, 'Emergência - Febre Hipertermia') # Muito grave\n",
    "    .when((col('Temperatura_Media') < 35.0) & (col('Oximetria_Media') < 90), 'Alerta - Hipotermia e Hipoxemia') # Combinação perigosa\n",
    "    .when((col('Temperatura_Media') > 38.5) & (col('Oximetria_Media') <= 92), 'Alerta - Febre Alta e Oxigenação Reduzida') # Grave\n",
    "    .when(col('Temperatura_Media') > 38.0, 'Atenção - Febre') # Atenção\n",
    "    .when((col('Oximetria_Media') >= 87) & (col('Oximetria_Media') <= 92), 'Atenção - Oxigenação Baixa') # Atenção\n",
    "    .when(col('Temperatura_Media') < 35.5, 'Atenção - Temperatura Baixa') # Atenção\n",
    "    .otherwise('Normal - Sem Alertas') # Normal\n",
    ")\n",
    "\n",
    "# Mapeamento de prioridade numérica para a Cor Indicativa (cores ajustadas para gravidade)\n",
    "df_resultado_final = df_com_legenda.withColumn('Cor Indicativa',\n",
    "    when(col('Legenda Gravidade') == 'Emergência - Oxigenação Crítica', '#8B0000') # Vermelho Escuro: Perigo Imediato\n",
    "    .when(col('Legenda Gravidade') == 'Emergência - Febre Hipertermia', '#DC143C') # Carmesim: Muito Crítico\n",
    "    .when(col('Legenda Gravidade') == 'Alerta - Hipotermia e Hipoxemia', '#FF4500') # Laranja Avermelhado: Urgência Elevada\n",
    "    .when(col('Legenda Gravidade') == 'Alerta - Febre Alta e Oxigenação Reduzida', '#FF8C00') # Laranja Escuro: Alerta Sério\n",
    "    .when(col('Legenda Gravidade') == 'Atenção - Febre', '#FFD700') # Dourado: Atenção Moderada\n",
    "    .when(col('Legenda Gravidade') == 'Atenção - Oxigenação Baixa', '#32CD32') # Verde Limão: Atenção Leve (mas ainda requer observação)\n",
    "    .when(col('Legenda Gravidade') == 'Atenção - Temperatura Baixa', '#4169E1') # Azul Real: Atenção Leve\n",
    "    .otherwise('#008000') # Verde Escuro: Tudo Certo\n",
    ")\n",
    "\n",
    "## Juntando Dados e Reestruturando Colunas\n",
    "\n",
    "### 1. Renomear `fk_paciente` para o Nome do Paciente\n",
    "\n",
    "df_final = df_resultado_final.join(\n",
    "    paciente_df,\n",
    "    df_resultado_final.fk_paciente == paciente_df.id_paciente,\n",
    "    \"left\"\n",
    ").withColumnRenamed(\"nome\", \"nome_paciente\") \\\n",
    " .drop(\"fk_paciente\") \\\n",
    " .drop(\"id_paciente\") \\\n",
    " .drop(\"cpf\") \\\n",
    " .drop(\"data_nascimento\") \\\n",
    " .drop(\"biometria\")\n",
    "\n",
    "# --- AJUSTE AQUI: Renomear e reestruturar colunas de data/hora ---\n",
    "# A coluna 'data_hora' agora representa a primeira medição do dia para aquele paciente.\n",
    "# A coluna 'data_agrupamento_temporaria' pode ser descartada ou renomeada, mas para manter a consistência,\n",
    "# vamos usar 'data_hora' para derivar 'data_chegada' e 'horario_chegada'.\n",
    "df_final = df_final.withColumn('data_chegada', to_date(col('data_hora'), \"yyyy-MM-dd'T'HH:mm:ss\").cast(DateType())) \\\n",
    "                     .withColumn('horario_chegada', date_format(col('data_hora'), \"HH:mm:ss\").cast(StringType())) \\\n",
    "                     .drop('data_hora') \\\n",
    "                     .drop('data_agrupamento_temporaria') # Remove a coluna temporária usada para o agrupamento\n",
    "\n",
    "# `join` com o `upa_df` e depois excluindo colunas desnecessarias.\n",
    "df_final = df_final.join(\n",
    "    upa_df,\n",
    "    df_final.fk_upa == upa_df.id_upa,\n",
    "    \"left\"\n",
    ").withColumnRenamed(\"nome\", \"nome_da_upa\") \\\n",
    " .drop(\"id_upa\") \\\n",
    " .drop(\"cnpj\") \\\n",
    " .drop(\"telefone\") \\\n",
    " .drop(\"capacidade_atendimento\") \\\n",
    " .drop(\"fk_endereco\")\n",
    "\n",
    "## Definir a ordem final das colunas\n",
    "\n",
    "colunas_finais_ordenadas = [\n",
    "    'nome_paciente',\n",
    "    'Oximetria_Media',\n",
    "    'Temperatura_Media',\n",
    "    'Legenda Gravidade',\n",
    "    'Cor Indicativa',\n",
    "    'data_chegada',\n",
    "    'horario_chegada',\n",
    "    'fk_upa',\n",
    "    'nome_da_upa'\n",
    "]\n",
    "\n",
    "\n",
    "df_final = df_final.select(colunas_finais_ordenadas)\n",
    "\n",
    "# Mostrar o DataFrame resultante\n",
    "df_final.show(120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "797407e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/16 23:37:29 WARN AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.\n",
      "25/06/16 23:37:30 WARN AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_final.coalesce(1) \\\n",
    "        .write \\\n",
    "        .option('header', 'true') \\\n",
    "        .mode('overwrite') \\\n",
    "        .csv('s3a://bucket-trusted-upa-connect-1/grafico_oximetria_temperatura.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efed1cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip install with root privileges is generally not a good idea. Try `python3 -m pip install --user` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib64/python3.7/site-packages (1.3.5)\n",
      "Requirement already satisfied: numpy>=1.17.3; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in /usr/local/lib64/python3.7/site-packages (from pandas) (1.21.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.17.0)\n",
      "'pandas' instalado com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip install with root privileges is generally not a good idea. Try `python3 -m pip install --user` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gspread in /usr/local/lib/python3.7/site-packages (3.6.0)\n",
      "Requirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.7/site-packages (from gspread) (2.40.2)\n",
      "Requirement already satisfied: requests>=2.2.1 in /usr/local/lib/python3.7/site-packages (from gspread) (2.31.0)\n",
      "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.7/site-packages (from gspread) (1.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/site-packages (from google-auth>=1.12.0->gspread) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/site-packages (from google-auth>=1.12.0->gspread) (4.9.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/site-packages (from google-auth>=1.12.0->gspread) (5.5.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib64/python3.7/site-packages (from requests>=2.2.1->gspread) (3.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests>=2.2.1->gspread) (2025.4.26)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests>=2.2.1->gspread) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests>=2.2.1->gspread) (1.26.20)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/site-packages (from google-auth-oauthlib>=0.4.1->gspread) (2.0.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.2.2)\n",
      "'gspread' instalado com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip install with root privileges is generally not a good idea. Try `python3 -m pip install --user` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.7/site-packages (1.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/site-packages (from google-auth-oauthlib) (2.0.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.7/site-packages (from google-auth-oauthlib) (2.40.2)\n",
      "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.31.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/site-packages (from google-auth>=2.15.0->google-auth-oauthlib) (4.9.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/site-packages (from google-auth>=2.15.0->google-auth-oauthlib) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/site-packages (from google-auth>=2.15.0->google-auth-oauthlib) (0.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib64/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2025.4.26)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (1.26.20)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.10)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-auth-oauthlib) (0.5.1)\n",
      "'google-auth-oauthlib' instalado com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip install with root privileges is generally not a good idea. Try `python3 -m pip install --user` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/site-packages (1.33.13)\n",
      "Requirement already satisfied: s3transfer<0.9.0,>=0.8.2 in /usr/local/lib/python3.7/site-packages (from boto3) (0.8.2)\n",
      "Requirement already satisfied: botocore<1.34.0,>=1.33.13 in /usr/local/lib/python3.7/site-packages (from boto3) (1.33.13)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4; python_version < \"3.10\" in /usr/local/lib/python3.7/site-packages (from botocore<1.34.0,>=1.33.13->boto3) (1.26.20)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/site-packages (from botocore<1.34.0,>=1.33.13->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.34.0,>=1.33.13->boto3) (1.17.0)\n",
      "'boto3' instalado com sucesso.\n",
      "Baixando credenciais do S3: s3://bucket-trusted-upa-connect-1/credenciais.json para /tmp/credenciais.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/boto3/compat.py:82: PythonDeprecationWarning: Boto3 will no longer support Python 3.7 starting December 13, 2023. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.8 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credenciais baixadas com sucesso.\n",
      "Enviando DataFrame final para a aba 'OximetriaPaciente'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Spark convertido para Pandas com sucesso.\n",
      "Aba 'OximetriaPaciente' encontrada e limpa.\n",
      "Dados do DataFrame final enviados com sucesso para a aba 'OximetriaPaciente'.\n",
      "Arquivo de credenciais temporário '/tmp/credenciais.json' removido.\n"
     ]
    }
   ],
   "source": [
    "# --- Instalação de bibliotecas (adicione esta seção no início do seu script) ---\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Função para instalar pacotes\n",
    "def install_package(package):\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"'{package}' instalado com sucesso.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao instalar '{package}': {e}\")\n",
    "        # Em ambientes de produção, você pode querer adicionar um exit(1) aqui\n",
    "        # para parar a execução se uma dependência crítica não puder ser instalada.\n",
    "\n",
    "# Instalar as bibliotecas necessárias\n",
    "install_package(\"pandas\")\n",
    "install_package(\"gspread\")\n",
    "install_package(\"google-auth-oauthlib\") # Necessário para google.oauth2.service_account.Credentials\n",
    "install_package(\"boto3\") # Para interagir com o S3\n",
    "# --- Fim da seção de instalação de bibliotecas ---\n",
    "\n",
    "\n",
    "# --- CÓDIGO PARA ENVIAR PARA O GOOGLE SHEETS ---\n",
    "import pandas as pd # <-- MOVIDO PARA AQUI PARA GARANTIR QUE 'pd' ESTEJA NO ESCOPO\n",
    "import gspread\n",
    "from google.oauth2.service_account import Credentials\n",
    "import boto3\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# === CONFIGURAÇÕES PARA O GOOGLE SHEETS ===\n",
    "GOOGLE_SHEET_ID = '1i6BfuZXPOcTp6BFAiVkpktOBym0HtakZacUKfDzu1zI'\n",
    "S3_BUCKET_CREDENTIALS = 'bucket-trusted-upa-connect-1'\n",
    "S3_KEY_CREDENTIALS = 'credenciais.json'\n",
    "LOCAL_CREDENTIALS_PATH = '/tmp/credenciais.json'\n",
    "\n",
    "# === AUTENTICAÇÃO GOOGLE ===\n",
    "print(f\"Baixando credenciais do S3: s3://{S3_BUCKET_CREDENTIALS}/{S3_KEY_CREDENTIALS} para {LOCAL_CREDENTIALS_PATH}...\")\n",
    "s3 = boto3.client('s3')\n",
    "try:\n",
    "    s3.download_file(S3_BUCKET_CREDENTIALS, S3_KEY_CREDENTIALS, LOCAL_CREDENTIALS_PATH)\n",
    "    print(\"Credenciais baixadas com sucesso.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao baixar credenciais do S3: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "scopes = [\"https://www.googleapis.com/auth/spreadsheets\", \"https://www.googleapis.com/auth/drive\"]\n",
    "credenciais = Credentials.from_service_account_file(LOCAL_CREDENTIALS_PATH, scopes=scopes)\n",
    "cliente = gspread.authorize(credenciais)\n",
    "planilha = cliente.open_by_key(GOOGLE_SHEET_ID)\n",
    "\n",
    "# === ENVIA O DATAFRAME FINAL PARA A NOVA ABA \"teste\" ===\n",
    "NOME_ABA_OXIMETRIA_PACIENTE = \"OximetriaPaciente\"\n",
    "print(f\"Enviando DataFrame final para a aba '{NOME_ABA_OXIMETRIA_PACIENTE}'...\")\n",
    "\n",
    "# Converter Spark DataFrame para Pandas DataFrame\n",
    "try:\n",
    "    df_pandas = df_final.toPandas()\n",
    "    print(\"DataFrame Spark convertido para Pandas com sucesso.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao converter Spark DataFrame para Pandas: {e}\")\n",
    "    print(\"O DataFrame pode ser muito grande para a memória do driver ou a sessão Spark está inválida.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# --- NOVO TRECHO: Ajustar tipagem das colunas para o Google Sheets ---\n",
    "# Apenas formata colunas de data/hora para string ISO 8601.\n",
    "# As demais colunas (numéricas, strings, etc.) são mantidas em seus tipos nativos no Pandas.\n",
    "# O gspread e o Google Sheets farão a inferência de tipo para elas.\n",
    "\n",
    "# Coluna 'data_chegada': assegurar que é string DD/MM/YYYY\n",
    "if 'data_chegada' in df_pandas.columns:\n",
    "    if pd.api.types.is_datetime64_any_dtype(df_pandas['data_chegada']):\n",
    "        df_pandas['data_chegada'] = df_pandas['data_chegada'].dt.strftime('%d/%m/%Y') # <-- MUDANÇA AQUI\n",
    "    elif pd.api.types.is_string_dtype(df_pandas['data_chegada']):\n",
    "        # Tentar converter strings que podem não estar em formato padrão para datetime,\n",
    "        # e depois formatar para DD/MM/YYYY. 'errors=coerce' transforma não-datas em NaT.\n",
    "        df_pandas['data_chegada'] = pd.to_datetime(df_pandas['data_chegada'], errors='coerce').dt.strftime('%d/%m/%Y') # <-- MUDANÇA AQUI\n",
    "    # Preencher valores nulos (NaT) com string vazia, pois None também pode causar problemas.\n",
    "    df_pandas['data_chegada'] = df_pandas['data_chegada'].fillna('')\n",
    "\n",
    "# Coluna 'horario_chegada': assegurar que é string HH:MM:SS\n",
    "if 'horario_chegada' in df_pandas.columns:\n",
    "    if pd.api.types.is_datetime64_any_dtype(df_pandas['horario_chegada']):\n",
    "        df_pandas['horario_chegada'] = df_pandas['horario_chegada'].dt.strftime('%H:%M:%S')\n",
    "    elif pd.api.types.is_string_dtype(df_pandas['horario_chegada']):\n",
    "        # Se já é string (como no seu caso vindo do Spark), apenas garanta que nulos sejam preenchidos.\n",
    "        df_pandas['horario_chegada'] = df_pandas['horario_chegada'].fillna('')\n",
    "\n",
    "\n",
    "# Nenhuma conversão global df_pandas.astype(str) é necessária aqui.\n",
    "# gspread é capaz de lidar com int, float, bool, e strings diretamente.\n",
    "\n",
    "dados = [df_pandas.columns.tolist()] + df_pandas.values.tolist()\n",
    "\n",
    "try:\n",
    "    aba = planilha.worksheet(NOME_ABA_OXIMETRIA_PACIENTE)\n",
    "    aba.clear()\n",
    "    print(f\"Aba '{NOME_ABA_OXIMETRIA_PACIENTE}' encontrada e limpa.\")\n",
    "except gspread.exceptions.WorksheetNotFound:\n",
    "    aba = planilha.add_worksheet(title=NOME_ABA_OXIMETRIA_PACIENTE, rows=str(len(dados) + 100), cols=str(len(df_pandas.columns) + 10))\n",
    "    print(f\"Aba '{NOME_ABA_OXIMETRIA_PACIENTE}' criada.\")\n",
    "\n",
    "try:\n",
    "    aba.update(dados)\n",
    "    print(f\"Dados do DataFrame final enviados com sucesso para a aba '{NOME_ABA_OXIMETRIA_PACIENTE}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao atualizar a aba do Google Sheets: {e}\")\n",
    "\n",
    "# Opcional: Remover o arquivo de credenciais temporário\n",
    "if os.path.exists(LOCAL_CREDENTIALS_PATH):\n",
    "    os.remove(LOCAL_CREDENTIALS_PATH)\n",
    "    print(f\"Arquivo de credenciais temporário '{LOCAL_CREDENTIALS_PATH}' removido.\")\n",
    "\n",
    "# Parar a sessão Spark\n",
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb41655f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
